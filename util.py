import nltk
# nltk.download('stopwords')
# nltk.download('punkt_tab')
# nltk.download('wordnet')
# nltk.download('averaged_perceptron_tagger_eng')
# nltk.download('stopwords')
# nltk.download('averaged_perceptron_tagger_eng')
# nltk.download('wordnet')


# corp = PlaintextCorpusReader(".", 'CorpusLenguajes.txt')
# texto_tokenizado = word_tokenize(corpus.raw())
# print("tokenizado:", texto_tokenizado)
# print("Sin sw:", quitarStopwords_eng(texto_tokenizado))
# print("Lematizado:", lematizar(quitarStopwords_eng(texto_tokenizado)))
# frecuencia = FreqDist(lematizar(quitarStopwords_eng(texto_tokenizado)))
# frecuencia.plot(20, show=True)
